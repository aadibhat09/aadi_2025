{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "layout: post\n",
    "title: Computer Bias Blog\n",
    "description: A blog for the Computer Bias team\n",
    "permalink: /posts/computer-bias/\n",
    "comments: true\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Popcorn Hack 1: Provide an example of a movie, TV show, video game, or software that demonstrates bias and specify who is affected by it. Explain a potential cause of this bias.\n",
    "\n",
    "Sometimes, media and technology can show bias by marginalizing certain minorities. This negatively impacts how people are perceived by others. A lack of diversity is a cause of this bias. An example is how AI software has been proven to misidentify people of color at higher rates than people that are white.\n",
    "\n",
    "<br>\n",
    "\n",
    "## Popcorn Hack 2: Think about a time when you felt a technology didn't work well for you. What was the issue, and how did it make you feel? Write a short paragraph describing the experience and suggest one way the technology could be improved to be more inclusive.\n",
    "\n",
    "Many times before, teachers would ask students to scan a QR code and fill out a form. I was unable to do this because I did not have a smartphone. This was frustrating because it was easy for everyone else but I had to ask others to send me the form. Adding a shortened link underneath every QR code could help to make this more inclusive.\n",
    "\n",
    "<br>\n",
    "\n",
    "## Popcorn Hack 3: Imagine you're designing a fitness tracking app. How could bias sneak into your appâ€™s recommendations or performance evaluations? Think about users with different physical abilities, ages, or health conditions. What features could you add to ensure the app is fair and inclusive for all users?\n",
    "\n",
    "If the software excludes users with impairments, older folks, or those with different health issues, or prioritizes particular body types or fitness levels, then the fitness tracking app could have some bias. To ensure that the app is fair and inclusive for all users,it should be able to provide adjustable objectives, adaptive training, and a variety of activity tracking options, such as wheelchair mobility or low-impact exercises.\n",
    "\n",
    "<br>\n",
    "\n",
    "## Homework Hack\n",
    "\n",
    "One example is how YouTube's recommendation algorithm usually favors content that is popular. This could probably limit diverse perspectives on the platform. This can also criticize certain demographics based on peoples' watch history. This also makes it harder for smaller creators to be seen. This bias could likely come from algorithms solely optimizing for user engagement, not diversity. A good solution is for YouTube to create a \"diverse discovery\" mode to recommend content from different creators to broaden the perspective of the user.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
